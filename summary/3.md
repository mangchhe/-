Google cloud, Container(docker, kubernetes), MSA
- 신규 기술들이 가상화, 추상화를 기반
- 문제시 추적하기 어려워짐

기존의 일반적인 모니터링 기반의 문제 탐색을 어렵게 함.
- 수시로 업데이트되는 MSA 상의 서비스와 의존관계
- 동적으로 변화하는 인프라
- 단일 요청을 보내지만, 여러 개의 예측할 수 없는 네트워크 홉을 통과해야 하는 구조 & 높은 Cardinality를 가진 지표

Observability
- 이미 경험한 장애 케이스를 탐지하는 수준의 모니터링을 넘어서 겪어보지 못한 새로운 현상에 대한 가시성을 제공
- 원인에 대한 질문에 답할 수 있는 시스템을 만들어야 한다.
- 루돌프 칼만 : 시스템의 출력으로부터 시스템의 상태를 이해할 수 있는 능력
- 로그나 실시간으로 수집되고 있는 모니터링 지표와 같은 출력을 통해 시스템의 상태를 이해할 수 있는 능력

TraceId
- 예외가 발생했을 때를 대비해 요청당 식별자 하나를 발급 모든 로그에 요청당 식별자를 남겨둔다면 문제 상황을 이해하는데 도움이 된다.

로그 문맥
- 로그가 일관성이 없으면 파악하기 힘들다.
- 로그 정형화가 필요하다.

거래 내력 조회 요청 
→ 유저 인증
→ 거래 내역 조회
호출이 있다고 한다면 기술적인 관점에서는 3개의 요청이지만 비즈니스 관점에서는 하나의 요청으로 본다.
서로가 연결되어 있어야 한다는 말이고 요청당 식별자(TraceId)를 다른 서비스와 공유하여 일관성을 유지해야 한다.
- 서로 다른 애플리케이션에 같은 Trace Id 전달
- 단일 요청이 분산되어 처리되는 과정을 추적하는 방법 = 분산 추적 = HTTP 헤더를 통해 Trace Id만 전달 해주면 됨
- 구글의 Dapper 논문 발표 이후 - Zipkin, Jaeger 오픈소스 분산 추적 도구 등장
- Spring Framework에서는 Sleuth라는 하위 프로젝트를 통해 분산 추적 가능

다양한 추적 문맥에 대한 표현법 존재
- 참여하는 모든 서비스가 동일한 규격을 준수하여 추적 문맥 전파가 잘 호환될 수 있을 때 극대화할 수 있다.
- World Wide Web Consortium (W3C) Trace Context 표준
  - B3 표현법 (X3-B3-*)
  - Jaeger 표현법 (uber*)
  - AWS X-Ray (X-Amzn-Trace-Id)
  - Google Cloud Trace (X-Cloud-Trace-Context)

토스페이먼츠 분산 추적 확장
- Trace Id보다 한 단계 더 상위에 해당하는 Global Trace Id를 정의하여 사용
  - 비즈니스 관점에서 하나의 요청이 아닌 하나의 사용자 시나리오 전체를 이해하는 상황을 맞이한다.
  - 시나리오 전체를 엮어줄 수 있는 Trace Id가 없어 로그 전체를 하나로 엮어줄 수 있는 Trace Id가 없어 빠르게 문제를 확인하는 것이 어렵다.

- 추적 문맥 전파 항목 추가
  - API를 호출한 클라이언트 버전, 서비스명, 서비스 버전, API 처리와 관련된 고객사, API 처리와 관련된 원천사 등 GlobalTraceId, TraceId, SpanId 이외에도 다양한 정보를 함께 전파
  - 문맥을 좀 더 이해할 수 있게 도와준다.

- 추적 범위 확장
  - MSA를 구성하는 서비스들에만 국한하지 않는다.
  - 서비스들 이외에도 다양한 인프라 구성 요소들로 이루어져 있다.
  - 시스템의 전체적인 가시성을 확보하기 위해 CDN, 방화벽, LB, DB에 이르기까지 TraceId만 있다면 전 구간의 로그를 찾아볼 수 있도록 구성해야 한다.
  - DB, TCP 서버와 같은 HTTP 헤더에 넣을 수 없는 구성 요소와의 통신은 어떻게 추적 문맥 전파?
    - DB는 쿼리의 주석 부분에 추적 문맥을 포함
    - TCP
      - L7 LB는 자신에게 접속한 클라이언트 IP 정보를 X-Forwarded-For와 같은 HTTP 헤더에 담아 서버에 전달해 줌으로써 서버가 실제 클라이언트 IP를 알 수 있게 해준다.
      - L4 LB에게 HTTP 프로토콜은 이해할 수 없는 바이트 덩어리이다.
      - X-Forwarded-For와 같은 추가적인 정보를 추가하지 못한다.
      - TCP 요청 본문을 그대로 유지하고 제일 앞줄에 PROXY라는 단어와 함께 Proxy Protocol이라는 규격을 만들어 요청 본문에 변경을 가하지 않고 추가적인 정보를 보낼 수 있도록 한다.

- Trace Id를 가능한 클라이언트로부터 생성되도록 한다.
  - 프론트엔드 로직은 서버와 통신을 시작하기 전부터 로직이 실행될 수 있고 경우에 따라 서버와 통신하기 이전에 사용자와 인터랙션이 발생할 수 있기 때문에 문제 발생 당시 문맥을 이해하기 위해서는 문맥을 이어줄 TraceId가 미리 발급되어 있어야 한다.

- 다양한 서비스 분석 시스템 연계
  - 에러 추적 : Sentry
  - APM : Pinpoint

Question
- 의도하지 않은 동일한 요청이 세 번 들어왔다. 사용자가 세 번 호출한 것인지, 인프라 내부 Retry 로직이 세 번 호출한 것인지 알 수 있을까요?
  - Trace Id를 이용하여 사용자에게 임시로 할당된 Session Id를 찾은 후 해당 Session Id와 관련된 최초 요청이 인입되는 Load Balancer 요청을 찾아보면 알 수 있다.
  - Access log, LB log 둘 다 동일 요청 건수가 존재한다면 클라이언트에 버그가 있지 않는 이상 사용자가 세 번 호출한 것이다.
- Feature-A API를 수정했을 때 어떤 서비스의 API들이 영향을 받는지 2-depth로 알고 싶다.
  - 각 Access log에는 요청을 보낸 서비스명을 포함하고 있고 클라이언트가 서버로 보낸 하나의 API 요청에서 파생된 요청들은 모두 동일한 Trace Id를 공유한다.
  - Access log에서 각 호출한 서비스명을 들여다본다면 API 간에 의존성을 알 수 있다.

분산 추적을 위한 추적 문맥 전파 기반을 활용해 테스트 환경을 개선한 사례
- A → B → C → D 서비스가 협업
  - D 서비스에 버그가 있는 것 같다. B에서 C서버로 특정한 데이터를 넘겨줌으로써 발생한 문제로 추정
  - 디버깅을 위해 B, D를 추가로 띄우고 특정 개발자 요청만 별도 서버로 들어오도록 만들고 싶다.
  - 하지만 그 작업을 위해 A, C 서비스를 추가 수정하려니 작업 규모가 커서 엄두가 나질 않는다.
  - 어떻게 해야 할까?
    - Istio라는 서비스 메시를 이용
    - 특정한 헤더 규칙을 만족하면 다른 서비스로 요청을 라우팅해 주는 기능이 존재
    - 헤더에 특정 값이 있을 경우 B, D 추가 생성된 서비스로 라우팅 되도록 설정함으로써 추가 수정 없이 디버깅 환경을 구성하는 것이 가능해진다.